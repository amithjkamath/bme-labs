{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMTi9N4e+Vf7JqConHslR4X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ubern-mia/bme-labs/blob/main/Session3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Session 3\n",
        "\n",
        "Today, we will look into what features a classifier deems important for the decision it takes.\n",
        "\n",
        "First, load the data againg (the same one you used last time)."
      ],
      "metadata": {
        "id": "Yoxiw15Jty5L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiQgcnj7tuBa"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "! cd \"/content\"\n",
        "uploaded = files.upload()\n",
        "\n",
        "measurements = \"/content/\" + list(uploaded.keys())[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As last time, define a training and testing split and define the feature columns. Then we will use a random forest classifier for the prediction. Instead of the cross-validation as last time, we use the full training set."
      ],
      "metadata": {
        "id": "K_RiIDqJKVlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import make_scorer, balanced_accuracy_score\n",
        "\n",
        "# define a mapping of the disease encoding back to strings\n",
        "diseasestatus = {0: \"Healthy\", 1: \"ASD\", 2: \"Epilepsy\"}\n",
        "\n",
        "measurements = pd.read_csv(\"/content/fsfaststats.csv\")\n",
        "\n",
        "# map the disease name to the encoding and make sure the age is a float\n",
        "measurements[\"Disease\"] = [diseasestatus[e] for e in measurements[\"Disease\"]]\n",
        "measurements[\"Age\"] = [float(e) for e in measurements[\"Age\"]]\n",
        "\n",
        "# X is the feature matrix we feed to the classifier, i.e. the measurements and the age of the subject\n",
        "features = list(set(measurements.columns) - set([\"Subject\", \"Disease\"]))\n",
        "X = measurements.loc[:, features]\n",
        "y = measurements[\"Disease\"]\n",
        "\n",
        "# Reserve 20% of the data for testing\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_index, test_index in sss.split(X, y):\n",
        "  print(\"Training set size: \" + str(len(train_index)))\n",
        "  print(\"Test set size: \" + str(len(test_index)))\n",
        "\n",
        "X_train = X.iloc[train_index, :]\n",
        "y_train = y.iloc[train_index]\n",
        "\n",
        "X_test = X.iloc[test_index, :]\n",
        "y_test = y.iloc[test_index]\n",
        "\n",
        "# Plug in the parameter settings that work well according to your experiments\n",
        "clf = RandomForestClassifier(n_estimators=200, max_depth=None, random_state=42)\n",
        "\n",
        "# Train the classifier and apply it to the test set\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "pVg3ai5GKCqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With this trained classifier, we can now get information on which features are the most important ones:"
      ],
      "metadata": {
        "id": "cimTY0ZvLDfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "featimportances = clf.feature_importances_\n",
        "\n",
        "# sort these in descending order and see which features they correspond to\n",
        "sortidx = (-featimportances).argsort()\n",
        "importances_sorted = featimportances[sortidx]\n",
        "featurenames_sorted = X_train.columns[sortidx]\n",
        "print(importances_sorted)\n",
        "print(featurenames_sorted)"
      ],
      "metadata": {
        "id": "O3FM2v87LU-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot the feature importances. Since they are so many, limit it to the top 15 features."
      ],
      "metadata": {
        "id": "2O7aUZeeNu2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "n_most_important = 20\n",
        "sns.barplot(x=importances_sorted[:n_most_important], \n",
        "            y=featurenames_sorted[:n_most_important])\n",
        "plt.title(\"Random forest feature importance\")\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fIPCC1b5NuHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you know roughly which features seem to be the most important ones. Now try to see if you can already see the importance by looking at them individually. For this, you can (as we did during the previous sessions), plot the features. Replace the example below where the left hippocampus is selected with the most important feature. Please do this for the top three according to your previous findings."
      ],
      "metadata": {
        "id": "4Y4RLk6EOx2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plotcols = list(set(measurements.columns) - set([\"Age\", \"Subject\", \"Disease\"]))\n",
        "feature = \"Left-Hippocampus\"\n",
        "\n",
        "sns.lmplot(x=\"Age\", y=feature, hue=\"Disease\", data=measurements, ci=95)\n",
        "plt.title(feature)\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "P5eHzC4-uN0u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
